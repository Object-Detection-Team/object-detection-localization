{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. Importing Required Libraries for YOLO Model andÂ forÂ Training",
   "id": "96dd6b42ef316eea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T16:16:09.009606Z",
     "start_time": "2025-11-28T16:16:08.095167Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install ultralytics torch torchvision",
   "id": "5adbf12eb07aa81c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in ./.venv/lib/python3.13/site-packages (8.3.227)\r\n",
      "Requirement already satisfied: torch in ./.venv/lib/python3.13/site-packages (2.9.0)\r\n",
      "Requirement already satisfied: torchvision in ./.venv/lib/python3.13/site-packages (0.24.0)\r\n",
      "Requirement already satisfied: numpy>=1.23.0 in ./.venv/lib/python3.13/site-packages (from ultralytics) (2.2.6)\r\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in ./.venv/lib/python3.13/site-packages (from ultralytics) (3.10.7)\r\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in ./.venv/lib/python3.13/site-packages (from ultralytics) (4.12.0.88)\r\n",
      "Requirement already satisfied: pillow>=7.1.2 in ./.venv/lib/python3.13/site-packages (from ultralytics) (12.0.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in ./.venv/lib/python3.13/site-packages (from ultralytics) (6.0.3)\r\n",
      "Requirement already satisfied: requests>=2.23.0 in ./.venv/lib/python3.13/site-packages (from ultralytics) (2.32.5)\r\n",
      "Requirement already satisfied: scipy>=1.4.1 in ./.venv/lib/python3.13/site-packages (from ultralytics) (1.16.3)\r\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.13/site-packages (from ultralytics) (7.1.3)\r\n",
      "Requirement already satisfied: polars in ./.venv/lib/python3.13/site-packages (from ultralytics) (1.35.2)\r\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.18 in ./.venv/lib/python3.13/site-packages (from ultralytics) (2.0.18)\r\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from torch) (3.20.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.13/site-packages (from torch) (4.15.0)\r\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.13/site-packages (from torch) (80.9.0)\r\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.13/site-packages (from torch) (1.14.0)\r\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./.venv/lib/python3.13/site-packages (from torch) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.13/site-packages (from torch) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec>=0.8.5 in ./.venv/lib/python3.13/site-packages (from torch) (2025.10.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.13/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\r\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.13/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.13/site-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.13/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\r\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.13/site-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\r\n",
      "Requirement already satisfied: pyparsing>=3 in ./.venv/lib/python3.13/site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.13/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\r\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests>=2.23.0->ultralytics) (3.4.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.13/site-packages (from requests>=2.23.0->ultralytics) (3.11)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests>=2.23.0->ultralytics) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.13/site-packages (from requests>=2.23.0->ultralytics) (2025.10.5)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.13/site-packages (from jinja2->torch) (3.0.3)\r\n",
      "Requirement already satisfied: polars-runtime-32==1.35.2 in ./.venv/lib/python3.13/site-packages (from polars->ultralytics) (1.35.2)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m25.1.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.3\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T12:46:11.940026Z",
     "start_time": "2025-12-17T12:46:04.140444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ultralytics import YOLO\n",
    "import torch"
   ],
   "id": "3d2ee025e94dde24",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.1 Randomly selecting dataset samples from the huge dataset,\n",
    "### 2.2 Downloading pre-labeled dataset from Kaggle"
   ],
   "id": "e480f65107a2b07"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### We will be using pre-labeled data. So this code block is not necessary anymore.",
   "id": "210aae2cbd0462c6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T12:26:08.728917Z",
     "start_time": "2025-12-17T12:26:03.209644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "def sample_dataset(source_dir, target_root_dir, sample_size=100):\n",
    "    \"\"\"\n",
    "    Scans the source directory for ALL subdirectories (classes),\n",
    "    selects a random subset of images from each, and copies them to a target directory.\n",
    "    \"\"\"\n",
    "\n",
    "    # Supported image extensions\n",
    "    valid_extensions = {\".jpg\", \".jpeg\"}\n",
    "\n",
    "    # Create the target root directory if it doesn't exist\n",
    "    if not os.path.exists(target_root_dir):\n",
    "        os.makedirs(target_root_dir)\n",
    "        print(f\"Created target root directory: {target_root_dir}\")\n",
    "\n",
    "    # AUTOMATICALLY get all subdirectories in the source folder\n",
    "    classes_to_process = [d for d in os.listdir(source_dir)\n",
    "                          if os.path.isdir(os.path.join(source_dir, d))]\n",
    "\n",
    "    print(f\"Found {len(classes_to_process)} classes. Processing all of them...\\n\")\n",
    "\n",
    "    total_copied = 0\n",
    "\n",
    "    for class_name in classes_to_process:\n",
    "        class_path = os.path.join(source_dir, class_name)\n",
    "\n",
    "        # List all valid image files\n",
    "        images = [f for f in os.listdir(class_path)\n",
    "                  if os.path.splitext(f)[1].lower() in valid_extensions]\n",
    "\n",
    "        # Determine sample count (take all if less than sample_size)\n",
    "        num_to_sample = min(len(images), sample_size)\n",
    "\n",
    "        if num_to_sample == 0:\n",
    "            print(f\"Warning: No images found in '{class_name}'. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Randomly select images\n",
    "        selected_images = random.sample(images, num_to_sample)\n",
    "\n",
    "        # Define new folder name (e.g., \"sampled-apple\")\n",
    "        new_class_name = f\"sampled-{class_name}\"\n",
    "        target_class_path = os.path.join(target_root_dir, new_class_name)\n",
    "\n",
    "        # Create class directory\n",
    "        if not os.path.exists(target_class_path):\n",
    "            os.makedirs(target_class_path)\n",
    "\n",
    "        # Copy images\n",
    "        for image in selected_images:\n",
    "            src_file = os.path.join(class_path, image)\n",
    "            dst_file = os.path.join(target_class_path, image)\n",
    "            shutil.copy2(src_file, dst_file)\n",
    "\n",
    "        print(f\"{class_name}: Copied {num_to_sample} images -> '{new_class_name}'\")\n",
    "        total_copied += num_to_sample\n",
    "\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Process completed. Total of {total_copied} images copied to '{target_root_dir}'.\")\n",
    "\n",
    "# --- CONFIGURATION & RUN ---\n",
    "\n",
    "# Set your folder paths here\n",
    "SOURCE_FOLDER = \"unlabeled-data\"\n",
    "TARGET_FOLDER = \"sampled-unlabeled-data\"\n",
    "SAMPLES_PER_CLASS = 100\n",
    "\n",
    "# Run directly\n",
    "sample_dataset(SOURCE_FOLDER, TARGET_FOLDER, sample_size=SAMPLES_PER_CLASS)"
   ],
   "id": "8bc0bb527f318186",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19 classes. Processing all of them...\n",
      "\n",
      "apple: Copied 100 images -> 'sampled-apple'\n",
      "bell pepper: Copied 100 images -> 'sampled-bell pepper'\n",
      "strawberry: Copied 100 images -> 'sampled-strawberry'\n",
      "avocado: Copied 100 images -> 'sampled-avocado'\n",
      "pomegranate: Copied 100 images -> 'sampled-pomegranate'\n",
      "pumpkin: Copied 100 images -> 'sampled-pumpkin'\n",
      "kiwi: Copied 100 images -> 'sampled-kiwi'\n",
      "lemon: Copied 100 images -> 'sampled-lemon'\n",
      "mandarine: Copied 100 images -> 'sampled-mandarine'\n",
      "grapefruit: Copied 100 images -> 'sampled-grapefruit'\n",
      "quince: Copied 100 images -> 'sampled-quince'\n",
      "coconut: Copied 100 images -> 'sampled-coconut'\n",
      "eggplant: Copied 100 images -> 'sampled-eggplant'\n",
      "banana: Copied 100 images -> 'sampled-banana'\n",
      "zucchini: Copied 100 images -> 'sampled-zucchini'\n",
      "pineapple: Copied 100 images -> 'sampled-pineapple'\n",
      "tomato: Copied 100 images -> 'sampled-tomato'\n",
      "persimmon: Copied 100 images -> 'sampled-persimmon'\n",
      "orange: Copied 100 images -> 'sampled-orange'\n",
      "----------------------------------------\n",
      "Process completed. Total of 1900 images copied to 'sampled-unlabeled-data'.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Downloading Pre-labeled Dataset From Kaggle",
   "id": "c0b6d9b54f5c0764"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T12:39:55.084149Z",
     "start_time": "2025-12-17T12:39:11.062786Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import kagglehub\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "downloaded_path = kagglehub.dataset_download(\"kapturovalexander/fruits-by-yolo-fruits-detection\")\n",
    "\n",
    "target_path = \"label-dataset\"\n",
    "\n",
    "\n",
    "if not os.path.exists(target_path):\n",
    "    shutil.copytree(downloaded_path, target_path)\n",
    "    print(f\"Dataset is copied to this path: {os.path.abspath(target_path)}\")\n",
    "else:\n",
    "    print(\"This path already exists.\")"
   ],
   "id": "70c17d88a7ab1b3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramazanyildiz/PycharmProjects/object-detection-localization/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/kapturovalexander/fruits-by-yolo-fruits-detection?dataset_version_number=11...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115M/115M [00:35<00:00, 3.36MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset is copied to this path: /Users/ramazanyildiz/PycharmProjects/object-detection-localization/label-dataset\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3. Importing Model (YOLOv8m)",
   "id": "100ec61bbed1e9ae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T12:46:15.569725Z",
     "start_time": "2025-12-17T12:46:15.369426Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = YOLO(\"yolov8m.pt\")\n",
    "print(model.info())"
   ],
   "id": "3f291da943580406",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv8m summary: 169 layers, 25,902,640 parameters, 0 gradients, 79.3 GFLOPs\n",
      "(169, 25902640, 0, 79.3204224)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T12:17:10.659063Z",
     "start_time": "2025-12-17T12:17:09.798907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Testing the model with a jpg file\n",
    "results = model.predict(source='https://ultralytics.com/images/bus.jpg', save=True, conf=0.5)\n",
    "\n",
    "for r in results:\n",
    "    r.show()"
   ],
   "id": "6817c9071016b116",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
      "image 1/1 /Users/ramazanyildiz/PycharmProjects/object-detection-localization/bus.jpg: 640x480 4 persons, 1 bus, 328.9ms\n",
      "Speed: 22.7ms preprocess, 328.9ms inference, 16.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001B[1m/Users/ramazanyildiz/PycharmProjects/object-detection-localization/runs/detect/predict\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4. Model Training",
   "id": "711e25dadf9864be"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-12-17T13:08:06.482337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results = model.train(\n",
    "    data='labeled-dataset/data.yaml',\n",
    "    epochs=50,\n",
    "    imgsz=640,\n",
    "    device='mps',\n",
    "    batch=4,\n",
    "    workers=0,\n",
    ")"
   ],
   "id": "ff499442e45b09e1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.239 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.227 ðŸš€ Python-3.13.0 torch-2.9.0 MPS (Apple M1)\n",
      "\u001B[34m\u001B[1mengine/trainer: \u001B[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=labeled-dataset/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8m.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train3, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/Users/ramazanyildiz/PycharmProjects/object-detection-localization/runs/detect/train3, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=0, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3780907  ultralytics.nn.modules.head.Detect           [9, [192, 384, 576]]          \n",
      "Model summary: 169 layers, 25,861,531 parameters, 25,861,515 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 475/475 items from pretrained weights\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### failed. no enough gpu. we will continue with google colab",
   "id": "e9de415b197d0928"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
